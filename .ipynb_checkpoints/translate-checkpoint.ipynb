{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ca6a0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import display, Image, clear_output\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import warnings\n",
    "from collections import Counter, deque\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4231af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "class_names = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f1d7d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17072fbac5bd4d4db2d81866f5c25d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, button_style='danger', description='Stop', icon='square', tooltip='Description')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:3@423.065] global /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_11nitadzeg/croot/opencv-suite_1691620374638/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read:  A\n",
      "Translated message:  A\n"
     ]
    }
   ],
   "source": [
    "#https://abauville.medium.com/display-your-live-webcam-feed-in-a-jupyter-notebook-using-opencv-d01eb75921d1\n",
    "\n",
    "# remove all warnings if \n",
    "demoing = True\n",
    "if demoing:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "else:\n",
    "    warnings.filterwarnings(\"default\")\n",
    "\n",
    "# establish which model to use\n",
    "chosen_model = \"inception\"\n",
    "assert(chosen_model in ['resnet', 'inception'])\n",
    "\n",
    "# establish data transforms for incoming webcam frames\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((299, 299) if chosen_model == \"inception\" else (224, 244)),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# instanciate appropriate model\n",
    "if chosen_model == 'inception':\n",
    "    model = models.inception_v3(pretrained=True)\n",
    "    model.aux_logits=False\n",
    "else:\n",
    "    model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "model.load_state_dict(torch.load(os.path.abspath(f\"./models/{chosen_model}\")))\n",
    "model.eval()\n",
    "\n",
    "buffer = deque([])\n",
    "\n",
    "message = []\n",
    "\n",
    "# stop button\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# display function\n",
    "def view(button):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    i = 0\n",
    "    while True:\n",
    "        # read frame from webcam\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        \n",
    "        # crop and resize the frame\n",
    "        crop_width, crop_height = 800, 800  # Adjust these values as per your requirements\n",
    "\n",
    "        # get the dimensions of the image\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # calculate coordinates for the crop\n",
    "        start_x = (width - crop_width) // 2\n",
    "        start_y = (height - crop_height) // 2\n",
    "\n",
    "        # crop the image\n",
    "        cropped_image = frame[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
    "    \n",
    "        frame = cropped_image.astype(np.float32)\n",
    "\n",
    "        # apply transforms to frame\n",
    "        new_frame = data_transforms(frame / 255).unsqueeze(0)\n",
    "\n",
    "        # make prediction\n",
    "        with torch.no_grad():\n",
    "            pred = class_names[torch.argmax(model(new_frame))]\n",
    "            confidence = torch.max(nn.Softmax()(model(new_frame))).item()\n",
    "            if confidence < 0.5:\n",
    "                pred = \"N/A\"\n",
    "            buffer.append(pred)\n",
    "        \n",
    "        # set up color of text to be overlayed on frame\n",
    "        color = (0, 255, 255)\n",
    "        \n",
    "        most_common = Counter(buffer).most_common(1)[0][0]\n",
    "        \n",
    "        if len(buffer) == 15:\n",
    "            buffer.popleft()\n",
    "            \n",
    "        # if timing is correct, read a letter to memory\n",
    "        if i % 15 == 0 and len(buffer) and most_common != \"N/A\":\n",
    "            message.append(most_common)\n",
    "            print(\"Read: \", most_common)\n",
    "            color = (0, 0, 0)\n",
    "            buffer.clear()\n",
    "            \n",
    "        if confidence > 0.5:\n",
    "            buffer.append(pred[0])\n",
    "            \n",
    "        # display frame with letter overlayed\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "        cv2.putText(frame,  \n",
    "                most_common,  \n",
    "                (50, 50),  \n",
    "                font, 1,  \n",
    "                color,  \n",
    "                2,  \n",
    "                cv2.LINE_4) \n",
    "        \n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        \n",
    "        # if stop button is pressed, stop camera and show result\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "            print(f\"Translated message: \", \"\".join(message))\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "            \n",
    "# run\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe01c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new-acv] *",
   "language": "python",
   "name": "conda-env-new-acv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
