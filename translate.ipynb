{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca6a0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import display, Image, clear_output\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "\n",
    "from collections import Counter, deque\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6893e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4231af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "class_names = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2f1d7d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1a6097b163429d9580206a374c9254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, button_style='danger', description='Stop', icon='square', tooltip='Description')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:72@56838.951] global /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_11nitadzeg/croot/opencv-suite_1691620374638/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADDING  W\n",
      "ADDING  W\n",
      "ADDING  F\n",
      "ADDING  F\n",
      "ADDING  G\n",
      "ADDING  H\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-78:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/akash/anaconda3/envs/new-acv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/akash/anaconda3/envs/new-acv/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/f5/l11znykj5sj86z8zydv6sbtm0000gn/T/ipykernel_42312/2989100875.py\", line 39, in view\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated message:  WWFFGH\n"
     ]
    }
   ],
   "source": [
    "#https://abauville.medium.com/display-your-live-webcam-feed-in-a-jupyter-notebook-using-opencv-d01eb75921d1\n",
    "\n",
    "chosen_model = \"inception\"\n",
    "\n",
    "model = models.inception_v3(pretrained=True)\n",
    "model.aux_logits=False\n",
    "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "model.load_state_dict(torch.load(os.path.abspath(f\"./models/{chosen_model}\")))\n",
    "model.eval()\n",
    "\n",
    "buffer = deque([])\n",
    "\n",
    "message = []\n",
    "\n",
    "# stop button\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# display function\n",
    "def view(button):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    i = 0\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        \n",
    "        # crop and resize the frame\n",
    "        crop_width, crop_height = 299, 299  # Adjust these values as per your requirements\n",
    "\n",
    "        # Get the dimensions of the image\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # Calculate coordinates for the crop\n",
    "        start_x = (width - crop_width) // 2\n",
    "        start_y = (height - crop_height) // 2\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = frame[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
    "        \n",
    "        frame = cv2.resize(frame, dsize=(200, 200), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "        \n",
    "        frame = cropped_image.astype(np.float32)\n",
    "\n",
    "        new_frame = data_transforms(frame / 255).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = class_names[torch.argmax(model(new_frame))]\n",
    "            confidence = torch.max(nn.Softmax()(model(new_frame))).item()\n",
    "            if confidence < 0.5:\n",
    "                pred = \"N/A\"\n",
    "            buffer.append(pred)\n",
    "        \n",
    "        color = (0, 255, 255)\n",
    "        \n",
    "        most_common = Counter(buffer).most_common(1)[0][0]\n",
    "        \n",
    "        if len(buffer) == 15:\n",
    "            buffer.popleft()\n",
    "            \n",
    "        if i % 15 == 0 and len(buffer) and most_common != \"N/A\":\n",
    "            message.append(most_common)\n",
    "            print(\"ADDING \", most_common)\n",
    "            color = (0, 0, 0)\n",
    "            buffer.clear()\n",
    "            \n",
    "        if confidence > 0.5:\n",
    "            buffer.append(pred[0])\n",
    "            \n",
    "            \n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "        cv2.putText(frame,  \n",
    "                most_common,  \n",
    "                (50, 50),  \n",
    "                font, 1,  \n",
    "                color,  \n",
    "                2,  \n",
    "                cv2.LINE_4) \n",
    "        \n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        \n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "            print(f\"Translated message: \", \"\".join(message))\n",
    "        i += 1\n",
    "\n",
    "            \n",
    "# run\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5723eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2920b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new-acv] *",
   "language": "python",
   "name": "conda-env-new-acv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
