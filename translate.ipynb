{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ca6a0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import display, Image, clear_output\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import warnings\n",
    "from collections import Counter, deque\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6893e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4231af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "class_names = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2f1d7d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c250f3bf61ad4933884f1bce25ad885d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, button_style='danger', description='Stop', icon='square', tooltip='Description')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read:  A\n",
      "Read:  K\n",
      "Read:  A\n",
      "Read:  S\n",
      "Read:  H\n",
      "Translated message:  AKASH\n"
     ]
    }
   ],
   "source": [
    "#https://abauville.medium.com/display-your-live-webcam-feed-in-a-jupyter-notebook-using-opencv-d01eb75921d1\n",
    "\n",
    "demoing = True\n",
    "if demoing:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "else:\n",
    "    warnings.filterwarnings(\"default\")\n",
    "    \n",
    "\n",
    "\n",
    "chosen_model = \"inception\"\n",
    "\n",
    "model = models.inception_v3(pretrained=True)\n",
    "model.aux_logits=False\n",
    "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "model.load_state_dict(torch.load(os.path.abspath(f\"./models/{chosen_model}\")))\n",
    "model.eval()\n",
    "\n",
    "buffer = deque([])\n",
    "\n",
    "message = []\n",
    "\n",
    "# stop button\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# display function\n",
    "def view(button):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    i = 0\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "        \n",
    "        # crop and resize the frame\n",
    "        crop_width, crop_height = 299, 299  # Adjust these values as per your requirements\n",
    "\n",
    "        # Get the dimensions of the image\n",
    "        height, width = frame.shape[:2]\n",
    "\n",
    "        # Calculate coordinates for the crop\n",
    "        start_x = (width - crop_width) // 2\n",
    "        start_y = (height - crop_height) // 2\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = frame[start_y:start_y + crop_height, start_x:start_x + crop_width]\n",
    "    \n",
    "        frame = cropped_image.astype(np.float32)\n",
    "\n",
    "        new_frame = data_transforms(frame / 255).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = class_names[torch.argmax(model(new_frame))]\n",
    "            confidence = torch.max(nn.Softmax()(model(new_frame))).item()\n",
    "            if confidence < 0.5:\n",
    "                pred = \"N/A\"\n",
    "            buffer.append(pred)\n",
    "        \n",
    "        color = (0, 255, 255)\n",
    "        \n",
    "        most_common = Counter(buffer).most_common(1)[0][0]\n",
    "        \n",
    "        if len(buffer) == 15:\n",
    "            buffer.popleft()\n",
    "            \n",
    "        if i % 15 == 0 and len(buffer) and most_common != \"N/A\":\n",
    "            message.append(most_common)\n",
    "            print(\"Read: \", most_common)\n",
    "            color = (0, 0, 0)\n",
    "            buffer.clear()\n",
    "            \n",
    "        if confidence > 0.5:\n",
    "            buffer.append(pred[0])\n",
    "            \n",
    "            \n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "        cv2.putText(frame,  \n",
    "                most_common,  \n",
    "                (50, 50),  \n",
    "                font, 1,  \n",
    "                color,  \n",
    "                2,  \n",
    "                cv2.LINE_4) \n",
    "        \n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        \n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "            print(f\"Translated message: \", \"\".join(message))\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "            \n",
    "# run\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5723eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2920b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new-acv] *",
   "language": "python",
   "name": "conda-env-new-acv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
